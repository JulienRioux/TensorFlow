{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification On California Census Data\n",
    "\n",
    "Find who whon less or equal to 50k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the data frame with the California Census Data\n",
    "df = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count         mean          std   min   25%   50%   75%  \\\n",
       "age             32561.0    38.581647    13.640433  17.0  28.0  37.0  48.0   \n",
       "education_num   32561.0    10.080679     2.572720   1.0   9.0  10.0  12.0   \n",
       "capital_gain    32561.0  1077.648844  7385.292085   0.0   0.0   0.0   0.0   \n",
       "capital_loss    32561.0    87.303830   402.960219   0.0   0.0   0.0   0.0   \n",
       "hours_per_week  32561.0    40.437456    12.347429   1.0  40.0  40.0  45.0   \n",
       "\n",
       "                    max  \n",
       "age                90.0  \n",
       "education_num      16.0  \n",
       "capital_gain    99999.0  \n",
       "capital_loss     4356.0  \n",
       "hours_per_week     99.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"income_bracket\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the target value for 0 and 1\n",
    "\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].apply(lambda x: 0 if x == ' <=50K' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"income_bracket\", axis=1)\n",
    "\n",
    "y = df[\"income_bracket\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the features\n",
    "feat_cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "\n",
      "\n",
      "Categorical: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'native_country']\n"
     ]
    }
   ],
   "source": [
    "# Separate the categorical cols to the numerical ones\n",
    "\n",
    "# numerical\n",
    "num_cols = []\n",
    "\n",
    "# Categorical\n",
    "cat_cols = []\n",
    "\n",
    "for col in feat_cols:\n",
    "    if X_train[col].dtype == \"object\":\n",
    "        cat_cols.append(col)\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "        \n",
    "print(\"Numerical:\",num_cols)\n",
    "print(\"\\n\")\n",
    "print(\"Categorical:\",cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf objects for every columns\n",
    "feat_cols = []\n",
    "\n",
    "# Transform the categorical value with hash bucket \n",
    "for col in cat_cols:\n",
    "    \n",
    "    uniqueValue = len(X_train[col].unique())\n",
    "    \n",
    "    # Using hashbucket\n",
    "    exec(f\"{col} = tf.feature_column.categorical_column_with_hash_bucket({'col'}, hash_bucket_size={uniqueValue})\")\n",
    "    \n",
    "    # create embedded columns out of the cateogrical feature\n",
    "    exec(f\"{col} = tf.feature_column.embedding_column({col}, dimension={uniqueValue})\")\n",
    "\n",
    "    exec(f\"feat_cols.append({col})\")\n",
    "\n",
    "for col in num_cols:\n",
    "    \n",
    "    exec(f\"{col} = tf.feature_column.numeric_column('{col}')\")\n",
    "    \n",
    "    exec(f\"feat_cols.append({col})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=9, dtype=tf.string), dimension=9, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120dda0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=16, dtype=tf.string), dimension=16, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120d518>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=7, dtype=tf.string), dimension=7, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120ddd8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=15, dtype=tf.string), dimension=15, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120de10>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=6, dtype=tf.string), dimension=6, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120d5c0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=5, dtype=tf.string), dimension=5, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120de80>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=2, dtype=tf.string), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120def0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=42, dtype=tf.string), dimension=42, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a1120df28>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tuning parameters\n",
    "\n",
    "batchSize=100\n",
    "numEpochs = 20000\n",
    "numSteps = 10000\n",
    "hiddenUnit = [10,20,20,20,10]\n",
    "dropOut = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input function\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=batchSize, \n",
    "                                                 num_epochs=numEpochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpytew64dv\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpytew64dv', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier (DNNClassifier)\n",
    "\n",
    "clf = tf.estimator.DNNClassifier(hidden_units=hiddenUnit, feature_columns=feat_cols, dropout=dropOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpytew64dv/model.ckpt.\n",
      "INFO:tensorflow:loss = 412.073, step = 1\n",
      "INFO:tensorflow:global_step/sec: 135.19\n",
      "INFO:tensorflow:loss = 46.1827, step = 101 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.649\n",
      "INFO:tensorflow:loss = 32.3489, step = 201 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.378\n",
      "INFO:tensorflow:loss = 43.0974, step = 301 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.263\n",
      "INFO:tensorflow:loss = 50.5656, step = 401 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.862\n",
      "INFO:tensorflow:loss = 41.3097, step = 501 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.565\n",
      "INFO:tensorflow:loss = 32.788, step = 601 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.468\n",
      "INFO:tensorflow:loss = 34.0014, step = 701 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.286\n",
      "INFO:tensorflow:loss = 49.3322, step = 801 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.346\n",
      "INFO:tensorflow:loss = 35.2704, step = 901 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.054\n",
      "INFO:tensorflow:loss = 46.0731, step = 1001 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.423\n",
      "INFO:tensorflow:loss = 36.0727, step = 1101 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.139\n",
      "INFO:tensorflow:loss = 36.5156, step = 1201 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.99\n",
      "INFO:tensorflow:loss = 38.2782, step = 1301 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.978\n",
      "INFO:tensorflow:loss = 41.3432, step = 1401 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.65\n",
      "INFO:tensorflow:loss = 45.7197, step = 1501 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.971\n",
      "INFO:tensorflow:loss = 43.257, step = 1601 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.429\n",
      "INFO:tensorflow:loss = 40.2025, step = 1701 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.84\n",
      "INFO:tensorflow:loss = 45.5429, step = 1801 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.026\n",
      "INFO:tensorflow:loss = 49.867, step = 1901 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.404\n",
      "INFO:tensorflow:loss = 31.5781, step = 2001 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.95\n",
      "INFO:tensorflow:loss = 29.5753, step = 2101 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.26\n",
      "INFO:tensorflow:loss = 39.4776, step = 2201 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.47\n",
      "INFO:tensorflow:loss = 36.8555, step = 2301 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.839\n",
      "INFO:tensorflow:loss = 35.6266, step = 2401 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.021\n",
      "INFO:tensorflow:loss = 40.0172, step = 2501 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.132\n",
      "INFO:tensorflow:loss = 41.5885, step = 2601 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.095\n",
      "INFO:tensorflow:loss = 38.6747, step = 2701 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.626\n",
      "INFO:tensorflow:loss = 43.3347, step = 2801 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.942\n",
      "INFO:tensorflow:loss = 27.6148, step = 2901 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.733\n",
      "INFO:tensorflow:loss = 45.7949, step = 3001 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.723\n",
      "INFO:tensorflow:loss = 40.1261, step = 3101 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.756\n",
      "INFO:tensorflow:loss = 36.6513, step = 3201 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.796\n",
      "INFO:tensorflow:loss = 29.045, step = 3301 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.216\n",
      "INFO:tensorflow:loss = 44.9357, step = 3401 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.399\n",
      "INFO:tensorflow:loss = 52.7963, step = 3501 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.369\n",
      "INFO:tensorflow:loss = 36.2799, step = 3601 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.684\n",
      "INFO:tensorflow:loss = 51.1574, step = 3701 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.523\n",
      "INFO:tensorflow:loss = 30.5395, step = 3801 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.943\n",
      "INFO:tensorflow:loss = 36.273, step = 3901 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.376\n",
      "INFO:tensorflow:loss = 36.239, step = 4001 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.241\n",
      "INFO:tensorflow:loss = 44.907, step = 4101 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.83\n",
      "INFO:tensorflow:loss = 34.9722, step = 4201 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.255\n",
      "INFO:tensorflow:loss = 40.4679, step = 4301 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.825\n",
      "INFO:tensorflow:loss = 50.97, step = 4401 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.903\n",
      "INFO:tensorflow:loss = 40.5984, step = 4501 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.466\n",
      "INFO:tensorflow:loss = 38.2827, step = 4601 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.695\n",
      "INFO:tensorflow:loss = 34.9953, step = 4701 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.647\n",
      "INFO:tensorflow:loss = 46.4156, step = 4801 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.899\n",
      "INFO:tensorflow:loss = 31.1373, step = 4901 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.887\n",
      "INFO:tensorflow:loss = 34.169, step = 5001 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.242\n",
      "INFO:tensorflow:loss = 35.7128, step = 5101 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.228\n",
      "INFO:tensorflow:loss = 31.1433, step = 5201 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.603\n",
      "INFO:tensorflow:loss = 34.5969, step = 5301 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.025\n",
      "INFO:tensorflow:loss = 38.9061, step = 5401 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.312\n",
      "INFO:tensorflow:loss = 35.0383, step = 5501 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.584\n",
      "INFO:tensorflow:loss = 29.2256, step = 5601 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.291\n",
      "INFO:tensorflow:loss = 35.2656, step = 5701 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.721\n",
      "INFO:tensorflow:loss = 29.7014, step = 5801 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.645\n",
      "INFO:tensorflow:loss = 37.0758, step = 5901 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.095\n",
      "INFO:tensorflow:loss = 42.5624, step = 6001 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.524\n",
      "INFO:tensorflow:loss = 30.4779, step = 6101 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.324\n",
      "INFO:tensorflow:loss = 34.4171, step = 6201 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.182\n",
      "INFO:tensorflow:loss = 33.259, step = 6301 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.902\n",
      "INFO:tensorflow:loss = 34.6772, step = 6401 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.585\n",
      "INFO:tensorflow:loss = 37.5621, step = 6501 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.455\n",
      "INFO:tensorflow:loss = 37.295, step = 6601 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.572\n",
      "INFO:tensorflow:loss = 35.5319, step = 6701 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.183\n",
      "INFO:tensorflow:loss = 44.5579, step = 6801 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.662\n",
      "INFO:tensorflow:loss = 41.8524, step = 6901 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.564\n",
      "INFO:tensorflow:loss = 45.4484, step = 7001 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.222\n",
      "INFO:tensorflow:loss = 33.4147, step = 7101 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.027\n",
      "INFO:tensorflow:loss = 42.1297, step = 7201 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.932\n",
      "INFO:tensorflow:loss = 32.6326, step = 7301 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.973\n",
      "INFO:tensorflow:loss = 34.3983, step = 7401 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.862\n",
      "INFO:tensorflow:loss = 31.0846, step = 7501 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.174\n",
      "INFO:tensorflow:loss = 31.4817, step = 7601 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.226\n",
      "INFO:tensorflow:loss = 44.2074, step = 7701 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.521\n",
      "INFO:tensorflow:loss = 38.0793, step = 7801 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.894\n",
      "INFO:tensorflow:loss = 26.1298, step = 7901 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.833\n",
      "INFO:tensorflow:loss = 41.6597, step = 8001 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.584\n",
      "INFO:tensorflow:loss = 40.6264, step = 8101 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.68\n",
      "INFO:tensorflow:loss = 40.76, step = 8201 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.695\n",
      "INFO:tensorflow:loss = 36.709, step = 8301 (0.604 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 162.275\n",
      "INFO:tensorflow:loss = 37.0871, step = 8401 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.24\n",
      "INFO:tensorflow:loss = 39.0764, step = 8501 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.162\n",
      "INFO:tensorflow:loss = 35.0023, step = 8601 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.251\n",
      "INFO:tensorflow:loss = 37.2984, step = 8701 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.511\n",
      "INFO:tensorflow:loss = 33.2957, step = 8801 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.713\n",
      "INFO:tensorflow:loss = 45.7001, step = 8901 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.566\n",
      "INFO:tensorflow:loss = 41.9354, step = 9001 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.803\n",
      "INFO:tensorflow:loss = 36.6156, step = 9101 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.201\n",
      "INFO:tensorflow:loss = 40.3436, step = 9201 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.597\n",
      "INFO:tensorflow:loss = 31.1461, step = 9301 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.985\n",
      "INFO:tensorflow:loss = 41.0656, step = 9401 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.553\n",
      "INFO:tensorflow:loss = 41.4369, step = 9501 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.182\n",
      "INFO:tensorflow:loss = 27.2263, step = 9601 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.581\n",
      "INFO:tensorflow:loss = 39.5755, step = 9701 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.561\n",
      "INFO:tensorflow:loss = 32.9931, step = 9801 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.466\n",
      "INFO:tensorflow:loss = 33.0398, step = 9901 (0.597 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpytew64dv/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 38.6371.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a1120e6d8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the test_datas\n",
    "clf.train(input_fn=input_func, steps=numSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input function for the test data\n",
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=batchSize, \n",
    "                                                      num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpytew64dv/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions dictionnary (0 if salary <=50K$ else 1)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for pred in list(clf.predict(input_fn=eval_input_func)):\n",
    "    \n",
    "    y_pred.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89      8196\n",
      "          1       0.72      0.47      0.57      2550\n",
      "\n",
      "avg / total       0.82      0.83      0.82     10746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
