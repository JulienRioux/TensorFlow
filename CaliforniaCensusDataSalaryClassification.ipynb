{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification On California Census Data\n",
    "\n",
    "Find who won less or equal to 50k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the data frame with the California Census Data\n",
    "df = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>32561.0</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count         mean          std   min   25%   50%   75%  \\\n",
       "age             32561.0    38.581647    13.640433  17.0  28.0  37.0  48.0   \n",
       "education_num   32561.0    10.080679     2.572720   1.0   9.0  10.0  12.0   \n",
       "capital_gain    32561.0  1077.648844  7385.292085   0.0   0.0   0.0   0.0   \n",
       "capital_loss    32561.0    87.303830   402.960219   0.0   0.0   0.0   0.0   \n",
       "hours_per_week  32561.0    40.437456    12.347429   1.0  40.0  40.0  45.0   \n",
       "\n",
       "                    max  \n",
       "age                90.0  \n",
       "education_num      16.0  \n",
       "capital_gain    99999.0  \n",
       "capital_loss     4356.0  \n",
       "hours_per_week     99.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"income_bracket\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the target value for 0 and 1\n",
    "\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].apply(lambda x: 0 if x == ' <=50K' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"income_bracket\", axis=1)\n",
    "\n",
    "y = df[\"income_bracket\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the features\n",
    "feat_cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "\n",
      "\n",
      "Categorical: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'native_country']\n"
     ]
    }
   ],
   "source": [
    "# Separate the categorical cols to the numerical ones\n",
    "\n",
    "# numerical\n",
    "num_cols = []\n",
    "\n",
    "# Categorical\n",
    "cat_cols = []\n",
    "\n",
    "for col in feat_cols:\n",
    "    if X_train[col].dtype == \"object\":\n",
    "        cat_cols.append(col)\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "        \n",
    "print(\"Numerical:\",num_cols)\n",
    "print(\"\\n\")\n",
    "print(\"Categorical:\",cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tf objects for every columns\n",
    "feat_cols = []\n",
    "\n",
    "# Transform the categorical value with hash bucket \n",
    "for col in cat_cols:\n",
    "    \n",
    "    uniqueValue = len(X_train[col].unique())\n",
    "    \n",
    "    # Using hashbucket\n",
    "    exec(f\"{col} = tf.feature_column.categorical_column_with_hash_bucket({'col'}, hash_bucket_size={uniqueValue})\")\n",
    "    \n",
    "    # create embedded columns out of the cateogrical feature\n",
    "    exec(f\"{col} = tf.feature_column.embedding_column({col}, dimension={uniqueValue})\")\n",
    "\n",
    "    exec(f\"feat_cols.append({col})\")\n",
    "\n",
    "# Create the numerical columns tf.feature_columns\n",
    "for col in num_cols:\n",
    "    \n",
    "    exec(f\"{col} = tf.feature_column.numeric_column('{col}')\")\n",
    "    \n",
    "    exec(f\"feat_cols.append({col})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=9, dtype=tf.string), dimension=9, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132ace80>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=16, dtype=tf.string), dimension=16, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132aceb8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=7, dtype=tf.string), dimension=7, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132acef0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=15, dtype=tf.string), dimension=15, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132acf28>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=6, dtype=tf.string), dimension=6, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132acf60>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=5, dtype=tf.string), dimension=5, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132acfd0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=2, dtype=tf.string), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132ae048>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=42, dtype=tf.string), dimension=42, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x1a132ae0b8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tuning parameters\n",
    "\n",
    "batchSize=100\n",
    "numEpochs = 20000\n",
    "numSteps = 10000\n",
    "hiddenUnit = [10,20,10]\n",
    "dropOut = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input function\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=batchSize, \n",
    "                                                 num_epochs=numEpochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpfaaji72k\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpfaaji72k', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier (DNNClassifier)\n",
    "\n",
    "clf = tf.estimator.DNNClassifier(hidden_units=hiddenUnit, feature_columns=feat_cols, dropout=dropOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpfaaji72k/model.ckpt.\n",
      "INFO:tensorflow:loss = 516.378, step = 1\n",
      "INFO:tensorflow:global_step/sec: 136.401\n",
      "INFO:tensorflow:loss = 77.8297, step = 101 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.904\n",
      "INFO:tensorflow:loss = 40.4072, step = 201 (0.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.367\n",
      "INFO:tensorflow:loss = 41.9062, step = 301 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.399\n",
      "INFO:tensorflow:loss = 25.5706, step = 401 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.253\n",
      "INFO:tensorflow:loss = 38.7525, step = 501 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.487\n",
      "INFO:tensorflow:loss = 46.8524, step = 601 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.017\n",
      "INFO:tensorflow:loss = 51.0231, step = 701 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.746\n",
      "INFO:tensorflow:loss = 37.8636, step = 801 (0.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.422\n",
      "INFO:tensorflow:loss = 34.478, step = 901 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.415\n",
      "INFO:tensorflow:loss = 45.7729, step = 1001 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.302\n",
      "INFO:tensorflow:loss = 43.4083, step = 1101 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.972\n",
      "INFO:tensorflow:loss = 50.4441, step = 1201 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.966\n",
      "INFO:tensorflow:loss = 36.3262, step = 1301 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.968\n",
      "INFO:tensorflow:loss = 36.4474, step = 1401 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.844\n",
      "INFO:tensorflow:loss = 37.1966, step = 1501 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.359\n",
      "INFO:tensorflow:loss = 42.5121, step = 1601 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.384\n",
      "INFO:tensorflow:loss = 38.3309, step = 1701 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.47\n",
      "INFO:tensorflow:loss = 42.8844, step = 1801 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.908\n",
      "INFO:tensorflow:loss = 45.2497, step = 1901 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.699\n",
      "INFO:tensorflow:loss = 36.0997, step = 2001 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.841\n",
      "INFO:tensorflow:loss = 43.5093, step = 2101 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.1\n",
      "INFO:tensorflow:loss = 37.9884, step = 2201 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.096\n",
      "INFO:tensorflow:loss = 38.5545, step = 2301 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.091\n",
      "INFO:tensorflow:loss = 38.0681, step = 2401 (0.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.169\n",
      "INFO:tensorflow:loss = 55.9222, step = 2501 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.618\n",
      "INFO:tensorflow:loss = 41.7804, step = 2601 (0.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.257\n",
      "INFO:tensorflow:loss = 50.3799, step = 2701 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.845\n",
      "INFO:tensorflow:loss = 41.9602, step = 2801 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.59\n",
      "INFO:tensorflow:loss = 52.5326, step = 2901 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.311\n",
      "INFO:tensorflow:loss = 40.5492, step = 3001 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.462\n",
      "INFO:tensorflow:loss = 33.621, step = 3101 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.667\n",
      "INFO:tensorflow:loss = 42.536, step = 3201 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.64\n",
      "INFO:tensorflow:loss = 50.6831, step = 3301 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.143\n",
      "INFO:tensorflow:loss = 40.9559, step = 3401 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.502\n",
      "INFO:tensorflow:loss = 46.8587, step = 3501 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.921\n",
      "INFO:tensorflow:loss = 41.7516, step = 3601 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.692\n",
      "INFO:tensorflow:loss = 37.3629, step = 3701 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.529\n",
      "INFO:tensorflow:loss = 48.5443, step = 3801 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.858\n",
      "INFO:tensorflow:loss = 30.9533, step = 3901 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.307\n",
      "INFO:tensorflow:loss = 45.7128, step = 4001 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.759\n",
      "INFO:tensorflow:loss = 44.7284, step = 4101 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.841\n",
      "INFO:tensorflow:loss = 37.1285, step = 4201 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.185\n",
      "INFO:tensorflow:loss = 45.1899, step = 4301 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.674\n",
      "INFO:tensorflow:loss = 40.4084, step = 4401 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.115\n",
      "INFO:tensorflow:loss = 41.244, step = 4501 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.326\n",
      "INFO:tensorflow:loss = 31.8083, step = 4601 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.308\n",
      "INFO:tensorflow:loss = 42.5105, step = 4701 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.159\n",
      "INFO:tensorflow:loss = 56.4189, step = 4801 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.569\n",
      "INFO:tensorflow:loss = 32.2995, step = 4901 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.999\n",
      "INFO:tensorflow:loss = 34.9527, step = 5001 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.687\n",
      "INFO:tensorflow:loss = 43.3208, step = 5101 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.218\n",
      "INFO:tensorflow:loss = 44.1021, step = 5201 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.613\n",
      "INFO:tensorflow:loss = 45.308, step = 5301 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.519\n",
      "INFO:tensorflow:loss = 37.9305, step = 5401 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.934\n",
      "INFO:tensorflow:loss = 32.5072, step = 5501 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.606\n",
      "INFO:tensorflow:loss = 43.1676, step = 5601 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.115\n",
      "INFO:tensorflow:loss = 37.563, step = 5701 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.191\n",
      "INFO:tensorflow:loss = 40.6849, step = 5801 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.32\n",
      "INFO:tensorflow:loss = 51.5371, step = 5901 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.619\n",
      "INFO:tensorflow:loss = 55.1179, step = 6001 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.032\n",
      "INFO:tensorflow:loss = 36.6751, step = 6101 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.902\n",
      "INFO:tensorflow:loss = 46.2359, step = 6201 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.818\n",
      "INFO:tensorflow:loss = 30.6096, step = 6301 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.122\n",
      "INFO:tensorflow:loss = 40.2429, step = 6401 (0.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.762\n",
      "INFO:tensorflow:loss = 33.5431, step = 6501 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.693\n",
      "INFO:tensorflow:loss = 37.77, step = 6601 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.012\n",
      "INFO:tensorflow:loss = 34.0468, step = 6701 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.107\n",
      "INFO:tensorflow:loss = 45.0094, step = 6801 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.452\n",
      "INFO:tensorflow:loss = 39.7147, step = 6901 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.16\n",
      "INFO:tensorflow:loss = 26.3145, step = 7001 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.748\n",
      "INFO:tensorflow:loss = 34.4381, step = 7101 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.634\n",
      "INFO:tensorflow:loss = 40.0643, step = 7201 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.26\n",
      "INFO:tensorflow:loss = 30.5501, step = 7301 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.941\n",
      "INFO:tensorflow:loss = 32.777, step = 7401 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.297\n",
      "INFO:tensorflow:loss = 45.0323, step = 7501 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.303\n",
      "INFO:tensorflow:loss = 35.4077, step = 7601 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.782\n",
      "INFO:tensorflow:loss = 42.3505, step = 7701 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.226\n",
      "INFO:tensorflow:loss = 32.3632, step = 7801 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.493\n",
      "INFO:tensorflow:loss = 44.4733, step = 7901 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.626\n",
      "INFO:tensorflow:loss = 44.9572, step = 8001 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.591\n",
      "INFO:tensorflow:loss = 32.5933, step = 8101 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.405\n",
      "INFO:tensorflow:loss = 39.8271, step = 8201 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.138\n",
      "INFO:tensorflow:loss = 46.8825, step = 8301 (0.657 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 162.332\n",
      "INFO:tensorflow:loss = 39.3632, step = 8401 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.118\n",
      "INFO:tensorflow:loss = 40.1968, step = 8501 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.413\n",
      "INFO:tensorflow:loss = 30.9891, step = 8601 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.682\n",
      "INFO:tensorflow:loss = 43.1131, step = 8701 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.461\n",
      "INFO:tensorflow:loss = 37.5496, step = 8801 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.539\n",
      "INFO:tensorflow:loss = 39.7885, step = 8901 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.404\n",
      "INFO:tensorflow:loss = 39.4162, step = 9001 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.214\n",
      "INFO:tensorflow:loss = 41.5216, step = 9101 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.247\n",
      "INFO:tensorflow:loss = 47.9226, step = 9201 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.074\n",
      "INFO:tensorflow:loss = 47.5437, step = 9301 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.425\n",
      "INFO:tensorflow:loss = 37.6379, step = 9401 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.335\n",
      "INFO:tensorflow:loss = 46.9619, step = 9501 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.47\n",
      "INFO:tensorflow:loss = 34.1951, step = 9601 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.195\n",
      "INFO:tensorflow:loss = 39.0979, step = 9701 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.306\n",
      "INFO:tensorflow:loss = 31.087, step = 9801 (1.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.344\n",
      "INFO:tensorflow:loss = 39.8034, step = 9901 (0.634 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpfaaji72k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 33.4067.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a132ae7b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the test_datas\n",
    "clf.train(input_fn=input_func, steps=numSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the input function for the test data\n",
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=len(X_test), \n",
    "                                                      num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/gf/bvnvfh0s21x1yrbw8vsz0mt00000gn/T/tmpfaaji72k/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions dictionnary (0 if salary <=50K$ else 1)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for pred in list(clf.predict(input_fn=pred_input_func)):\n",
    "    \n",
    "    y_pred.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89      7436\n",
      "          1       0.64      0.59      0.62      2333\n",
      "\n",
      "avg / total       0.82      0.82      0.82      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check our results on a classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
