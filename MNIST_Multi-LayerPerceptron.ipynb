{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Create a variable with a temporary file for this data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how its stored\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's see this image\n",
    "sample = mnist.train.images[999].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEICAYAAACj9mr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAABZFJREFUeJzt3b1tG1kYQNHhYgEnTpUxl/pgB1IXVAcqwB2IXYgdsA8p\npyOnmzjiZrvAwlczXFP8Ec9J+Th8kKCLZ/PDzGy32w0Av/LHqTcAnC+BAJJAAEkggCQQQBIIIAkE\nkAQCSAIBJIEA0p/7vuHLly+7m5ubj9gLcAQ/fvwYfv78OZuydu9A3NzcDNvtdv9dAWdhPp9PXuuf\nGEASCCAJBJAEAkgCASSBAJJAAEkggCQQQBIIIAkEkAQCSAIBJIEAkkAASSCAJBBAEgggCQSQBAJI\nAgEkgQCSQABJIIAkEEASCCAJBJAEAkgCASSBAJJAAEkggCQQQBIIIAkEkAQCSAIBJIEAkkAASSCA\nJBBAEgggCQSQBAJIAgEkgQCSQABJIIAkEED689Qb4LhWq9VBrvP4+HiQ64y5v79/9/Vv376NXuP2\n9vZQ27k6ThBAEgggCQSQBAJIAgEkgQCSQABpttvt9nrDfD7fbbfbD9oO75kyw3Cs+YRL8vz8/O7r\ny+XySDs5D/P5fNhut7Mpa50ggCQQQBIIIAkEkAQCSAIBJIEAkkAAyaDUmXh4eBhds16vj7CT67Pv\n38ClMygFHIRAAEkggCQQQBIIIAkEkAQCSAIBJE/WOpLZbNJcylkYuwPTMAzDYrE4wk6G4e7u7sM/\n4+3tbXTNtT6dywkCSAIBJIEAkkAASSCAJBBAEgggmYMYMeU78qenpyPsZJrX19d3X7/W7/Pf42fS\nnCCAJBBAEgggCQSQBAJIAgEkgQCSQADJoNSIzWYzuuZYT7waG4Iahssa+pkyhHYMq9VqdM1yuTzC\nTs6PEwSQBAJIAgEkgQCSQABJIIAkEEASCCAZlLogU+5c9fLycoSdjJsyBHWMp2ZNMWUYzqAUwH8I\nBJAEAkgCASSBAJJAAEkggDTb7XZ7vWE+n++22+0Hbef8XNL3+Yfy/Pz829d4fHw8wE6OY9+/gUs3\nn8+H7XY7m7LWCQJIAgEkgQCSQABJIIAkEEASCCAJBJDcMGbElCdVTXni1SUNU13SkNMUU34//JoT\nBJAEAkgCASSBAJJAAEkggCQQQBIIIBmUOoApw1Rjdy16eHgYvcZ6vZ68p2txf38/umbK74dfc4IA\nkkAASSCAJBBAEgggCQSQBAJI5iDOxMvLy0GuM/YksM1mM3qNKWvOZSZjsVicegufmhMEkAQCSAIB\nJIEAkkAASSCAJBBAEgggGZT6ZA5xc5RzerLW2A1hlsvlkXZynZwggCQQQBIIIAkEkAQCSAIBJIEA\nkkAAyaDUlXl6ejr1FvZyqDtt8f84QQBJIIAkEEASCCAJBJAEAkgCASRzEJ/Mw8PDu6+fyxOxhmEY\nnp+fT70FRjhBAEkggCQQQBIIIAkEkAQCSAIBJIEAkkGpC/L29ja65lwGoaYMQXkq1vlzggCSQABJ\nIIAkEEASCCAJBJAEAkjmIC7I3d3dqbcw2WKxOPUWOAAnCCAJBJAEAkgCASSBAJJAAEkggCQQQDIo\ndSZWq9Wpt7CX19fXd1+/vb090k74SE4QQBIIIAkEkAQCSAIBJIEAkkAASSCAZFDqTGw2m1Nv4R9T\nnoplEOo6OEEASSCAJBBAEgggCQSQBAJIAgEkcxBnYsqTqNbr9W9/zv39/eia5XL525/D5+AEASSB\nAJJAAEkggCQQQBIIIAkEkAQCSAalzsSUQalL+hw+BycIIAkEkAQCSAIBJIEAkkAASSCAJBBAMih1\nJqY8qWq32x1hJ/AvJwggCQSQBAJIAgEkgQCSQABJIIAkEEASCCAJBJAEAkgCASSBAJJAAEkggCQQ\nQNo7EF+/fv2IfQBH8v3797epa2f73qVoNpu9DsOgEnC5/trtdndTFu4dCOB6+D8IIAkEkAQCSAIB\nJIEAkkAASSCAJBBAEggg/Q1Q4r5K63P0wAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c22d81be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=80)\n",
    "plt.imshow(sample, cmap='Greys')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's define the basics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001     # How quickly we adjust the cost function\n",
    "training_epochs = 45\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10    # 0 to 9\n",
    "n_samples = mnist.train.num_examples     #55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten shape of the handwritten digits image (28x28)\n",
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define the shape of our neural network (bigger it is, longer it is to train)\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build this model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \"\"\"\n",
    "    x: Placeholder for data input\n",
    "    weights: Dict of weights\n",
    "    biases: Dict of biases values\n",
    "    \"\"\"\n",
    "    \n",
    "    # First hidden layer with RELU activation\n",
    "    # X * W + b\n",
    "    layer_1 = tf.add(tf.matmul(x,weights[\"h1\"]), biases[\"b1\"])\n",
    "    # RELU(X * W + b) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights[\"h2\"]), biaises[\"b2\"])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output Layer\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights[\"out\"]), biases[\"out\"])\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.variable\n",
    "A tf.variable is a modifiable tensor that live in tensorflow graphs of interactions and can be use and modify in computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create the weights dictionary\n",
    "weights = {\n",
    "    # Matrix of normally distributed values (n_input rows by n_hidden_1 columns)\n",
    "    \"h1\": tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    # Matrix of normally distributed values (n_hidden_1 rows by n_hidden_2 columns)\n",
    "    \"h2\": tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    # Matrix of normally distributed values (n_hidden_2 rows by n_classes)\n",
    "    \"out\": tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create the biais dictionary\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set placeholders for x and y\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = multilayer_perceptron(x, weights, biaises)\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cost + Optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsamp, ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_12:0' shape=(1,) dtype=int64>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(ysamp,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAEVCAYAAAAcvnu6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgGkBAJICQSQEgggJRBASiCA1P8BGdLBv+OALBkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c4828cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=80)\n",
    "plt.imshow(Xsamp.reshape(28,28), cmap='Greys')\n",
    "plt.title(\"Label: {}\".format(ysamp.argmax()))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost: 149.6697\n",
      "Epoch: 2 cost: 40.2604\n",
      "Epoch: 3 cost: 24.9755\n",
      "Epoch: 4 cost: 17.2530\n",
      "Epoch: 5 cost: 12.3407\n",
      "Epoch: 6 cost: 9.2374\n",
      "Epoch: 7 cost: 6.7103\n",
      "Epoch: 8 cost: 4.9345\n",
      "Epoch: 9 cost: 3.5578\n",
      "Epoch: 10 cost: 2.7305\n",
      "Epoch: 11 cost: 1.9642\n",
      "Epoch: 12 cost: 1.5122\n",
      "Epoch: 13 cost: 1.1965\n",
      "Epoch: 14 cost: 0.9176\n",
      "Epoch: 15 cost: 0.7464\n",
      "Epoch: 16 cost: 0.5953\n",
      "Epoch: 17 cost: 0.4995\n",
      "Epoch: 18 cost: 0.5458\n",
      "Epoch: 19 cost: 0.4707\n",
      "Epoch: 20 cost: 0.4623\n",
      "Epoch: 21 cost: 0.3683\n",
      "Epoch: 22 cost: 0.3841\n",
      "Epoch: 23 cost: 0.3247\n",
      "Epoch: 24 cost: 0.2490\n",
      "Epoch: 25 cost: 0.3089\n",
      "Epoch: 26 cost: 0.3483\n",
      "Epoch: 27 cost: 0.2632\n",
      "Epoch: 28 cost: 0.2977\n",
      "Epoch: 29 cost: 0.2141\n",
      "Epoch: 30 cost: 0.2594\n",
      "Epoch: 31 cost: 0.2270\n",
      "Epoch: 32 cost: 0.2575\n",
      "Epoch: 33 cost: 0.2129\n",
      "Epoch: 34 cost: 0.2630\n",
      "Epoch: 35 cost: 0.1936\n",
      "Epoch: 36 cost: 0.2274\n",
      "Epoch: 37 cost: 0.2000\n",
      "Epoch: 38 cost: 0.2551\n",
      "Epoch: 39 cost: 0.1483\n",
      "Epoch: 40 cost: 0.1890\n",
      "Epoch: 41 cost: 0.2680\n",
      "Epoch: 42 cost: 0.1656\n",
      "Epoch: 43 cost: 0.1481\n",
      "Epoch: 44 cost: 0.1621\n",
      "Epoch: 45 cost: 0.1984\n",
      "Models has completed 45 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    # Convert the total num of batches (number of batches we have to run) into integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {} cost: {:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Models has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Equal_1:0\", shape=(?,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take the average of correct predictions\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_5:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96210003"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the tensor\n",
    "accuracy.eval({x:mnist.test.images, y:mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
